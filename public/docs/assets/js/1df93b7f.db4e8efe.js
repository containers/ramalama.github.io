"use strict";(globalThis.webpackChunkdocsite=globalThis.webpackChunkdocsite||[]).push([[583],{5579:(e,i,s)=>{s.r(i),s.d(i,{default:()=>g});var n=s(4164),t=s(8774),a=s(4586),r=s(1656),o=s(1107);const c={features:"features_t9lD",featureIcon:"featureIcon_GA8l"};var l=s(4848);const d=[{title:"Multiple Model Support",icon:"\ud83e\udd16",description:(0,l.jsx)(l.Fragment,{children:"Run models from HuggingFace, ModelScope, Ollama, and OCI registries. Supports popular formats like GGUF and more."})},{title:"REST API & Chat Interface",icon:"\ud83d\udcac",description:(0,l.jsx)(l.Fragment,{children:"Interact with models through a REST API or use the built-in chat interface. Perfect for both application development and direct interaction."})},{title:"RAG Support",icon:"\ud83d\udcda",description:(0,l.jsx)(l.Fragment,{children:"Built-in support for Retrieval Augmented Generation (RAG). Convert your documents into vector databases and enhance model responses with your data."})},{title:"Cross-Platform",icon:"\ud83d\udda5\ufe0f",description:(0,l.jsx)(l.Fragment,{children:"Works on Linux, macOS, and Windows (via WSL2). Supports both Podman and Docker as container engines."})},{title:"Performance Benchmarking",icon:"\ud83d\udcca",description:(0,l.jsx)(l.Fragment,{children:"Built-in tools to benchmark and measure model performance. Calculate perplexity and compare different models."})},{title:"Active Community",icon:"\ud83d\udc65",description:(0,l.jsx)(l.Fragment,{children:"Join our active Matrix community for support and discussions. Open source and welcoming contributions."})}];function m({title:e,description:i,icon:s}){return(0,l.jsxs)("div",{className:(0,n.A)("col col--4"),children:[(0,l.jsx)("div",{className:"text--center",children:(0,l.jsx)("span",{className:c.featureIcon,children:s})}),(0,l.jsxs)("div",{className:"text--center padding-horiz--md",children:[(0,l.jsx)(o.A,{as:"h3",children:e}),(0,l.jsx)("p",{children:i})]})]})}function h(){return(0,l.jsx)("section",{className:c.features,children:(0,l.jsx)("div",{className:"container",children:(0,l.jsx)("div",{className:"row",children:d.map((e,i)=>(0,l.jsx)(m,{...e},i))})})})}const u={heroBanner:"heroBanner_qdFl",heroLogo:"heroLogo_U6bI",buttons:"buttons_AeoN",highlights:"highlights_myJb",quickstart:"quickstart_J02g"};function x(){const{siteConfig:e}=(0,a.A)();return(0,l.jsx)("header",{className:(0,n.A)("hero hero--primary",u.heroBanner),children:(0,l.jsxs)("div",{className:"container",children:[(0,l.jsx)("img",{src:"/img/ramalama-logo-full-horiz.svg",alt:"RamaLama Logo",className:u.heroLogo}),(0,l.jsx)("p",{className:"hero__subtitle",children:"Run AI models locally with the simplicity of containers"}),(0,l.jsxs)("div",{className:u.buttons,children:[(0,l.jsx)(t.A,{className:"button button--secondary button--lg",to:"/docs/getting-started/installation",children:"Get Started \u2192"}),(0,l.jsx)(t.A,{className:"button button--outline button--secondary button--lg",href:"https://matrix.to/#/#ramalama:fedoraproject.org",children:"Join Community"})]})]})})}function p(){return(0,l.jsx)("section",{className:u.highlights,children:(0,l.jsx)("div",{className:"container",children:(0,l.jsxs)("div",{className:"row",children:[(0,l.jsx)("div",{className:"col col--4",children:(0,l.jsxs)("div",{className:"text--center padding-horiz--md",children:[(0,l.jsx)("h3",{children:"Simple & Familiar"}),(0,l.jsx)("p",{children:"Use familiar container commands to work with AI models. Pull, run, and serve models just like you would with Docker or Podman."})]})}),(0,l.jsx)("div",{className:"col col--4",children:(0,l.jsxs)("div",{className:"text--center padding-horiz--md",children:[(0,l.jsx)("h3",{children:"Hardware Optimized"}),(0,l.jsx)("p",{children:"Automatically detects your GPU and pulls optimized container images for NVIDIA, AMD, Intel, Apple Silicon and more."})]})}),(0,l.jsx)("div",{className:"col col--4",children:(0,l.jsxs)("div",{className:"text--center padding-horiz--md",children:[(0,l.jsx)("h3",{children:"Secure by Default"}),(0,l.jsx)("p",{children:"Run models in rootless containers with read-only mounts, network isolation, and automatic cleanup of temporary data."})]})})]})})})}function j(){return(0,l.jsx)("section",{className:u.quickstart,children:(0,l.jsx)("div",{className:"container",children:(0,l.jsxs)("div",{className:"row",children:[(0,l.jsxs)("div",{className:"col col--6",children:[(0,l.jsx)(o.A,{as:"h2",children:"Quick Start"}),(0,l.jsx)("p",{children:"Install RamaLama and start running AI models in minutes:"}),(0,l.jsx)("pre",{children:(0,l.jsxs)("code",{children:["# Install via script (Linux/macOS)",(0,l.jsx)("br",{}),"curl -fsSL https://ramalama.ai/install.sh | bash",(0,l.jsx)("br",{}),(0,l.jsx)("br",{}),"# Run your first model",(0,l.jsx)("br",{}),"ramalama run granite3-moe"]})})]}),(0,l.jsxs)("div",{className:"col col--6",children:[(0,l.jsx)(o.A,{as:"h2",children:"Supported Registries"}),(0,l.jsxs)("ul",{children:[(0,l.jsx)("li",{children:"HuggingFace"}),(0,l.jsx)("li",{children:"ModelScope"}),(0,l.jsx)("li",{children:"Ollama"}),(0,l.jsx)("li",{children:"OCI Container Registries (Quay.io, Docker Hub, etc.)"})]})]})]})})})}function g(){const{siteConfig:e}=(0,a.A)();return(0,l.jsxs)(r.A,{title:`${e.title} - Run AI Models with Container Simplicity`,description:"RamaLama makes working with AI simple and straightforward by using OCI containers. Run models locally with automatic hardware optimization and security by default.",children:[(0,l.jsx)(x,{}),(0,l.jsxs)("main",{children:[(0,l.jsx)(p,{}),(0,l.jsx)(j,{}),(0,l.jsx)(h,{})]})]})}}}]);