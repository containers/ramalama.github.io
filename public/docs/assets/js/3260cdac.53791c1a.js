"use strict";(globalThis.webpackChunkdocsite=globalThis.webpackChunkdocsite||[]).push([[115],{2112(e,n,r){r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>d,default:()=>h,frontMatter:()=>t,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"platform-guides/cann","title":"cann","description":"Platform-specific setup guide","source":"@site/docs/platform-guides/cann.mdx","sourceDirName":"platform-guides","slug":"/platform-guides/cann","permalink":"/docs/platform-guides/cann","draft":false,"unlisted":false,"editUrl":"https://github.com/containers/ramalama/edit/main/docsite/platform-guides/cann.mdx","tags":[],"version":"current","frontMatter":{"title":"cann","description":"Platform-specific setup guide"},"sidebar":"docs","previous":{"title":"Platform Guides","permalink":"/docs/category/platform-guides"},"next":{"title":"cuda","permalink":"/docs/platform-guides/cuda"}}');var a=r(4848),i=r(8453);const t={title:"cann",description:"Platform-specific setup guide"},d="cann",l={},c=[{value:"Background",id:"background",level:2},{value:"Hardware",id:"hardware",level:2},{value:"Ascend NPU",id:"ascend-npu",level:3},{value:"Model",id:"model",level:2},{value:"Docker",id:"docker",level:2},{value:"Install the Ascend driver",id:"install-the-ascend-driver",level:3},{value:"Build Images",id:"build-images",level:3}];function o(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"cann",children:"cann"})}),"\n",(0,a.jsx)(n.h1,{id:"setting-up-ramalama-with-ascend-npu-support-on-linux-systems",children:"Setting Up RamaLama with Ascend NPU Support on Linux systems"}),"\n",(0,a.jsx)(n.p,{children:"This guide walks through the steps required to set up RamaLama with Ascend NPU support."}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#background",children:"Background"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#hardware",children:"Hardware"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#model",children:"Model"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#docker",children:"Docker"})}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"background",children:"Background"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Ascend NPU"})," is a range of AI processors using Neural Processing Unit. It will efficiently handle matrix-matrix multiplication, dot-product and scalars."]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"CANN"})," (Compute Architecture for Neural Networks) is a heterogeneous computing architecture for AI scenarios, providing support for multiple AI frameworks on the top and serving AI processors and programming at the bottom. It plays a crucial role in bridging the gap between upper and lower layers, and is a key platform for improving the computing efficiency of Ascend AI processors. Meanwhile, it offers a highly efficient and easy-to-use programming interface for diverse application scenarios, allowing users to rapidly build AI applications and services based on the Ascend platform."]}),"\n",(0,a.jsx)(n.h2,{id:"hardware",children:"Hardware"}),"\n",(0,a.jsx)(n.h3,{id:"ascend-npu",children:"Ascend NPU"}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Verified devices"})}),"\n",(0,a.jsx)(n.p,{children:"Table Supported Hardware List:"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"Ascend NPU"}),(0,a.jsx)(n.th,{children:"Status"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"Atlas A2 Training series"}),(0,a.jsx)(n.td,{children:"Support"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"Atlas 800I A2 Inference series"}),(0,a.jsx)(n.td,{children:"Support"})]})]})]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.em,{children:"Notes:"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["If you have trouble with Ascend NPU device, please create an issue with ",(0,a.jsx)(n.strong,{children:"[CANN]"})," prefix/tag."]}),"\n",(0,a.jsx)(n.li,{children:'If you are running successfully with an Ascend NPU device, please help update the "Supported Hardware List" table above.'}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"model",children:"Model"}),"\n",(0,a.jsxs)(n.p,{children:["Currently, Ascend NPU acceleration is only supported when the llama.cpp backend is selected. For supported models, please refer to the page ",(0,a.jsx)(n.a,{href:"https://github.com/ggml-org/llama.cpp/blob/master/docs/backend/CANN.md",children:"llama.cpp/backend/CANN.md"}),"."]}),"\n",(0,a.jsx)(n.h2,{id:"docker",children:"Docker"}),"\n",(0,a.jsx)(n.h3,{id:"install-the-ascend-driver",children:"Install the Ascend driver"}),"\n",(0,a.jsxs)(n.p,{children:["This provides NPU acceleration using the AI cores of your Ascend NPU. And ",(0,a.jsx)(n.a,{href:"https://www.hiascend.com/en/software/cann",children:"CANN"})," is a hierarchical APIs to help you to quickly build AI applications and service based on Ascend NPU."]}),"\n",(0,a.jsxs)(n.p,{children:["For more information about Ascend NPU in ",(0,a.jsx)(n.a,{href:"https://www.hiascend.com/en/",children:"Ascend Community"}),"."]}),"\n",(0,a.jsxs)(n.p,{children:["Make sure to have the CANN toolkit installed. You can download it from here: ",(0,a.jsx)(n.a,{href:"https://www.hiascend.com/developer/download/community/result?module=cann",children:"CANN Toolkit"}),"\nMake sure the Ascend Docker runtime is installed. You can download it from here: ",(0,a.jsx)(n.a,{href:"https://www.hiascend.com/document/detail/en/mindx-dl/300/dluserguide/clusterscheduling/dlug_installation_02_000025.html",children:"Ascend-docker-runtime"})]}),"\n",(0,a.jsx)(n.h3,{id:"build-images",children:"Build Images"}),"\n",(0,a.jsxs)(n.p,{children:["Go to ",(0,a.jsx)(n.code,{children:"ramalama"})," directory and build using make."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"make build IMAGE=cann\nmake install\n"})}),"\n",(0,a.jsx)(n.p,{children:"You can test with:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"export ASCEND_VISIBLE_DEVICES=0\nramalama --image quay.io/ramalama/cann:latest serve -d -p 8080 -name ollama://smollm:135m\n"})}),"\n",(0,a.jsx)(n.p,{children:"In a window see the running podman container."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'$ podman ps\nCONTAINER ID   IMAGE                                                         COMMAND                  CREATED             STATUS             PORTS                                          NAMES\n80fc31c131b0   quay.io/ramalama/cann:latest                                  "/bin/bash -c \'expor\u2026"   About an hour ago   Up About an hour                                                  ame\n'})}),"\n",(0,a.jsxs)(n.p,{children:["Other using guides see RamaLama (",(0,a.jsx)(n.a,{href:"https://github.com/containers/ramalama/blob/main/README.md",children:"README.md"}),")"]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.em,{children:"Mar 2025, Originally compiled"})})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(o,{...e})}):o(e)}},8453(e,n,r){r.d(n,{R:()=>t,x:()=>d});var s=r(6540);const a={},i=s.createContext(a);function t(e){const n=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:t(e.components),s.createElement(i.Provider,{value:n},e.children)}}}]);