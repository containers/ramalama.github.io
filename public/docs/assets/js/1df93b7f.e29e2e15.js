"use strict";(globalThis.webpackChunkdocsite=globalThis.webpackChunkdocsite||[]).push([[583],{5579(e,i,s){s.r(i),s.d(i,{default:()=>A});var n=s(4164),a=s(8774),t=s(4586),r=s(1656),o=s(1107);const l="features_t9lD",c="featureIcon_GA8l";var d=s(4848);const m=[{title:"Multiple Model Support",icon:"\ud83e\udd16",description:(0,d.jsx)(d.Fragment,{children:"Run models from HuggingFace, ModelScope, Ollama, and OCI registries. Supports popular formats like GGUF and more."})},{title:"REST API & Chat Interface",icon:"\ud83d\udcac",description:(0,d.jsx)(d.Fragment,{children:"Interact with models through a REST API or use the built-in chat interface. Perfect for both application development and direct interaction."})},{title:"RAG Support",icon:"\ud83d\udcda",description:(0,d.jsx)(d.Fragment,{children:"Built-in support for Retrieval Augmented Generation (RAG). Convert your documents into vector databases and enhance model responses with your data."})},{title:"Cross-Platform",icon:"\ud83d\udda5\ufe0f",description:(0,d.jsx)(d.Fragment,{children:"Works on Linux, macOS, and Windows (via WSL2). Supports both Podman and Docker as container engines."})},{title:"Performance Benchmarking",icon:"\ud83d\udcca",description:(0,d.jsx)(d.Fragment,{children:"Built-in tools to benchmark and measure model performance. Calculate perplexity and compare different models."})},{title:"Active Community",icon:"\ud83d\udc65",description:(0,d.jsx)(d.Fragment,{children:"Join our active Matrix community for support and discussions. Open source and welcoming contributions."})}];function h({title:e,description:i,icon:s}){return(0,d.jsxs)("div",{className:(0,n.A)("col col--4"),children:[(0,d.jsx)("div",{className:"text--center",children:(0,d.jsx)("span",{className:c,children:s})}),(0,d.jsxs)("div",{className:"text--center padding-horiz--md",children:[(0,d.jsx)(o.A,{as:"h3",children:e}),(0,d.jsx)("p",{children:i})]})]})}function u(){return(0,d.jsx)("section",{className:l,children:(0,d.jsx)("div",{className:"container",children:(0,d.jsx)("div",{className:"row",children:m.map((e,i)=>(0,d.jsx)(h,{...e},i))})})})}const x="heroBanner_qdFl",p="heroLogo_U6bI",j="buttons_AeoN",g="highlights_myJb",f="quickstart_J02g";function v(){const{siteConfig:e}=(0,t.A)();return(0,d.jsx)("header",{className:(0,n.A)("hero hero--primary",x),children:(0,d.jsxs)("div",{className:"container",children:[(0,d.jsx)("img",{src:"/img/ramalama-logo-full-horiz.svg",alt:"RamaLama Logo",className:p}),(0,d.jsx)("p",{className:"hero__subtitle",children:"Run AI models locally with the simplicity of containers"}),(0,d.jsxs)("div",{className:j,children:[(0,d.jsx)(a.A,{className:"button button--secondary button--lg",to:"/docs/getting-started/installation",children:"Get Started \u2192"}),(0,d.jsx)(a.A,{className:"button button--outline button--secondary button--lg",href:"https://matrix.to/#/#ramalama:fedoraproject.org",children:"Join Community"})]})]})})}function b(){return(0,d.jsx)("section",{className:g,children:(0,d.jsx)("div",{className:"container",children:(0,d.jsxs)("div",{className:"row",children:[(0,d.jsx)("div",{className:"col col--4",children:(0,d.jsxs)("div",{className:"text--center padding-horiz--md",children:[(0,d.jsx)("h3",{children:"Simple & Familiar"}),(0,d.jsx)("p",{children:"Use familiar container commands to work with AI models. Pull, run, and serve models just like you would with Docker or Podman."})]})}),(0,d.jsx)("div",{className:"col col--4",children:(0,d.jsxs)("div",{className:"text--center padding-horiz--md",children:[(0,d.jsx)("h3",{children:"Hardware Optimized"}),(0,d.jsx)("p",{children:"Automatically detects your GPU and pulls optimized container images for NVIDIA, AMD, Intel, Apple Silicon and more."})]})}),(0,d.jsx)("div",{className:"col col--4",children:(0,d.jsxs)("div",{className:"text--center padding-horiz--md",children:[(0,d.jsx)("h3",{children:"Secure by Default"}),(0,d.jsx)("p",{children:"Run models in rootless containers with read-only mounts, network isolation, and automatic cleanup of temporary data."})]})})]})})})}function N(){return(0,d.jsx)("section",{className:f,children:(0,d.jsx)("div",{className:"container",children:(0,d.jsxs)("div",{className:"row",children:[(0,d.jsxs)("div",{className:"col col--6",children:[(0,d.jsx)(o.A,{as:"h2",children:"Quick Start"}),(0,d.jsx)("p",{children:"Install RamaLama and start running AI models in minutes:"}),(0,d.jsx)("pre",{children:(0,d.jsxs)("code",{children:["# Install via script (Linux/macOS)",(0,d.jsx)("br",{}),"curl -fsSL https://ramalama.ai/install.sh | bash",(0,d.jsx)("br",{}),(0,d.jsx)("br",{}),"# Run your first model",(0,d.jsx)("br",{}),"ramalama run granite3-moe"]})})]}),(0,d.jsxs)("div",{className:"col col--6",children:[(0,d.jsx)(o.A,{as:"h2",children:"Supported Registries"}),(0,d.jsxs)("ul",{children:[(0,d.jsx)("li",{children:"HuggingFace"}),(0,d.jsx)("li",{children:"ModelScope"}),(0,d.jsx)("li",{children:"Ollama"}),(0,d.jsx)("li",{children:"OCI Container Registries (Quay.io, Docker Hub, etc.)"})]})]})]})})})}function A(){const{siteConfig:e}=(0,t.A)();return(0,d.jsxs)(r.A,{title:`${e.title} - Run AI Models with Container Simplicity`,description:"RamaLama makes working with AI simple and straightforward by using OCI containers. Run models locally with automatic hardware optimization and security by default.",children:[(0,d.jsx)(v,{}),(0,d.jsxs)("main",{children:[(0,d.jsx)(b,{}),(0,d.jsx)(N,{}),(0,d.jsx)(u,{})]})]})}}}]);