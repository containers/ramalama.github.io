"use strict";(globalThis.webpackChunkdocsite=globalThis.webpackChunkdocsite||[]).push([[632],{2386(e,n,i){i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>o,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"platform-guides/cuda","title":"cuda","description":"Platform-specific setup guide","source":"@site/docs/platform-guides/cuda.mdx","sourceDirName":"platform-guides","slug":"/platform-guides/cuda","permalink":"/docs/platform-guides/cuda","draft":false,"unlisted":false,"editUrl":"https://github.com/containers/ramalama/edit/main/docsite/platform-guides/cuda.mdx","tags":[],"version":"current","frontMatter":{"title":"cuda","description":"Platform-specific setup guide"},"sidebar":"docs","previous":{"title":"cann","permalink":"/docs/platform-guides/cann"},"next":{"title":"macos","permalink":"/docs/platform-guides/macos"}}');var a=i(4848),s=i(8453);const o={title:"cuda",description:"Platform-specific setup guide"},r="cuda",l={},d=[{value:"Install the NVIDIA Container Toolkit",id:"install-the-nvidia-container-toolkit",level:2},{value:"Installation using dnf/yum (For RPM based distros like Fedora)",id:"installation-using-dnfyum-for-rpm-based-distros-like-fedora",level:3},{value:"Setting Up CUDA Support",id:"setting-up-cuda-support",level:2},{value:"Testing the Setup",id:"testing-the-setup",level:2},{value:"CUDA_VISIBLE_DEVICES",id:"cuda_visible_devices",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"CUDA Updates",id:"cuda-updates",level:3},{value:"See Also",id:"see-also",level:2}];function c(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"cuda",children:"cuda"})}),"\n",(0,a.jsx)(n.h1,{id:"setting-up-ramalama-with-cuda-support-on-linux-systems",children:"Setting Up RamaLama with CUDA Support on Linux systems"}),"\n",(0,a.jsx)(n.p,{children:"This guide walks through the steps required to set up RamaLama with CUDA support."}),"\n",(0,a.jsx)(n.h2,{id:"install-the-nvidia-container-toolkit",children:"Install the NVIDIA Container Toolkit"}),"\n",(0,a.jsxs)(n.p,{children:["Follow the installation instructions provided in the ",(0,a.jsx)(n.a,{href:"https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html",children:"NVIDIA Container Toolkit installation guide"}),"."]}),"\n",(0,a.jsx)(n.h3,{id:"installation-using-dnfyum-for-rpm-based-distros-like-fedora",children:"Installation using dnf/yum (For RPM based distros like Fedora)"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Install the NVIDIA Container Toolkit packages"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash"})}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"sudo dnf install -y nvidia-container-toolkit"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"\n:::note\n The NVIDIA Container Toolkit is required on the host for running CUDA in containers.\n:::\n:::note\n If the above installation is not working for you and you are running Fedora, try removing it and using the [COPR](https://copr.fedorainfracloud.org/coprs/g/ai-ml/nvidia-container-toolkit/).\n:::\n\n### Installation using APT (For Debian based distros like Ubuntu)\n\n* Configure the Production Repository\n\n   ```bash\ncurl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | \\\n   sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg\n\n   curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\n   sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n   sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\n"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Update the packages list from the repository"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash"})}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"sudo apt-get update"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"\n* Install the NVIDIA Container Toolkit packages\n\n   ```bash\nsudo apt-get install -y nvidia-container-toolkit\n"})}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsx)(n.p,{children:"The NVIDIA Container Toolkit is required for WSL to have CUDA resources while running a container."})}),"\n",(0,a.jsx)(n.h2,{id:"setting-up-cuda-support",children:"Setting Up CUDA Support"}),"\n",(0,a.jsxs)(n.p,{children:["For additional information see:  ",(0,a.jsx)(n.a,{href:"https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/cdi-support.html",children:"Support for Container Device Interface"})]}),"\n",(0,a.jsx)(n.h1,{id:"generate-the-cdi-specification-file",children:"Generate the CDI specification file"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"sudo nvidia-ctk cdi generate --output=/etc/cdi/nvidia.yaml\n"})}),"\n",(0,a.jsx)(n.h1,{id:"check-the-names-of-the-generated-devices",children:"Check the names of the generated devices"}),"\n",(0,a.jsx)(n.p,{children:"Open and edit the NVIDIA container runtime configuration:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"nvidia-ctk cdi list\nINFO[0000] Found 1 CDI devices\nnvidia.com/gpu=all\n"})}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsx)(n.p,{children:"Generate a new CDI specification after any configuration change most notably when the driver is upgraded!"})}),"\n",(0,a.jsx)(n.h2,{id:"testing-the-setup",children:"Testing the Setup"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Based on this Documentation:"}),"  ",(0,a.jsx)(n.a,{href:"https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/sample-workload.html",children:"Running a Sample Workload"})]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h1,{id:"test-the-installation",children:(0,a.jsx)(n.strong,{children:"Test the Installation"})}),"\n",(0,a.jsx)(n.p,{children:"Run the following command to verify setup:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"podman run --rm --device=nvidia.com/gpu=all fedora nvidia-smi\n"})}),"\n",(0,a.jsx)(n.h1,{id:"expected-output",children:(0,a.jsx)(n.strong,{children:"Expected Output"})}),"\n",(0,a.jsx)(n.p,{children:"Verify everything is configured correctly, with output similar to this:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:"Thu Dec  5 19:58:40 2024\n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 565.72                 Driver Version: 566.14         CUDA Version: 12.7     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA GeForce RTX 3080        On  |   00000000:09:00.0  On |                  N/A |\n| 34%   24C    P5             31W /  380W |     867MiB /  10240MiB |      7%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n\n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|    0   N/A  N/A        35      G   /Xwayland                                   N/A      |\n|    0   N/A  N/A        35      G   /Xwayland                                   N/A      |\n+-----------------------------------------------------------------------------------------+\n"})}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsxs)(n.p,{children:["On systems that have SELinux enabled, it may be necessary to turn on the ",(0,a.jsx)(n.code,{children:"container_use_devices"})," boolean in order to run the ",(0,a.jsx)(n.code,{children:"nvidia-smi"})," command successfully from a container."]})}),"\n",(0,a.jsx)(n.p,{children:"To check the status of the boolean, run the following:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"getsebool container_use_devices\n"})}),"\n",(0,a.jsxs)(n.p,{children:["If the result of the command shows that the boolean is ",(0,a.jsx)(n.code,{children:"off"}),", run the following to turn the boolean on:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"sudo setsebool -P container_use_devices 1\n"})}),"\n",(0,a.jsx)(n.h3,{id:"cuda_visible_devices",children:"CUDA_VISIBLE_DEVICES"}),"\n",(0,a.jsxs)(n.p,{children:["RamaLama respects the ",(0,a.jsx)(n.code,{children:"CUDA_VISIBLE_DEVICES"})," environment variable if it's already set in your environment. If not set, RamaLama will default to using all the GPU detected by nvidia-smi."]}),"\n",(0,a.jsx)(n.p,{children:"You can specify which GPU devices should be visible to RamaLama by setting this variable before running RamaLama commands:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'export CUDA_VISIBLE_DEVICES="0,1"  # Use GPUs 0 and 1\nramalama run granite\n'})}),"\n",(0,a.jsx)(n.p,{children:"This is particularly useful in multi-GPU systems where you want to dedicate specific GPUs to different workloads."}),"\n",(0,a.jsxs)(n.p,{children:["If the ",(0,a.jsx)(n.code,{children:"CUDA_VISIBLE_DEVICES"})," environment variable is set to an empty string, RamaLama will default to using the CPU."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'export CUDA_VISIBLE_DEVICES=""  # Defaults to CPU\nramalama run granite\n'})}),"\n",(0,a.jsx)(n.p,{children:"To revert to using all available GPUs, unset the environment variable:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"unset CUDA_VISIBLE_DEVICES\n"})}),"\n",(0,a.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,a.jsx)(n.h3,{id:"cuda-updates",children:"CUDA Updates"}),"\n",(0,a.jsx)(n.p,{children:"On some CUDA software updates, RamaLama stops working complaining about missing shared NVIDIA libraries for example:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"ramalama run granite\nError: crun: cannot stat `/lib64/libEGL_nvidia.so.565.77`: No such file or directory: OCI runtime attempted to invoke a command that was not found\n"})}),"\n",(0,a.jsx)(n.p,{children:"Because the CUDA version is updated, the CDI specification file needs to be recreated."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"sudo nvidia-ctk cdi generate --output=/etc/cdi/nvidia.yaml\n"})}),"\n",(0,a.jsx)(n.h2,{id:"see-also",children:"See Also"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.a,{href:"/docs/commands/ramalama/",children:"ramalama(1)"}),", ",(0,a.jsx)(n.a,{href:"https://github.com/containers/podman/blob/main/docs/source/markdown/podman.1.md",children:"podman(1)"})]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsxs)(n.em,{children:["Jan 2025, Originally compiled by Dan Walsh <",(0,a.jsx)(n.a,{href:"mailto:dwalsh@redhat.com",children:"dwalsh@redhat.com"}),">"]})})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},8453(e,n,i){i.d(n,{R:()=>o,x:()=>r});var t=i(6540);const a={},s=t.createContext(a);function o(e){const n=t.useContext(s);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),t.createElement(s.Provider,{value:n},e.children)}}}]);