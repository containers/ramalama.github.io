<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-configuration/conf" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Configuration File | RamaLama</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://ramalama.ai/docs/img/logo.svg"><meta data-rh="true" name="twitter:image" content="https://ramalama.ai/docs/img/logo.svg"><meta data-rh="true" property="og:url" content="https://ramalama.ai/docs/configuration/conf"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Configuration File | RamaLama"><meta data-rh="true" name="description" content="Configuration file reference"><meta data-rh="true" property="og:description" content="Configuration file reference"><link data-rh="true" rel="icon" href="/docs/img/favicon.png"><link data-rh="true" rel="canonical" href="https://ramalama.ai/docs/configuration/conf"><link data-rh="true" rel="alternate" href="https://ramalama.ai/docs/configuration/conf" hreflang="en"><link data-rh="true" rel="alternate" href="https://ramalama.ai/docs/configuration/conf" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Configuration","item":"https://ramalama.ai/docs/category/configuration"},{"@type":"ListItem","position":2,"name":"Configuration File","item":"https://ramalama.ai/docs/configuration/conf"}]}</script><link rel="stylesheet" href="/docs/assets/css/styles.e9c79a02.css">
<script src="/docs/assets/js/runtime~main.aa6380f1.js" defer="defer"></script>
<script src="/docs/assets/js/main.d1f5fb2b.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/docs/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/docs/"><div class="navbar__logo"><img src="/docs/img/logo.svg" alt="RamaLama Logo" class="themedComponent_mlkZ themedComponent--light_NVdE" height="40" width="40"><img src="/docs/img/logo.svg" alt="RamaLama Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU" height="40" width="40"></div><b class="navbar__title text--truncate">RamaLama</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/introduction">Docs</a><a href="https://blog.ramalama.com" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Blog<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/containers/ramalama" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/introduction"><span title="Introduction" class="linkLabel_WmDU">Introduction</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/docs/category/getting-started"><span title="Getting Started" class="categoryLinkLabel_W154">Getting Started</span></a><button aria-label="Expand sidebar category &#x27;Getting Started&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/docs/category/configuration"><span title="Configuration" class="categoryLinkLabel_W154">Configuration</span></a><button aria-label="Collapse sidebar category &#x27;Configuration&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/configuration/conf"><span title="Configuration File" class="linkLabel_WmDU">Configuration File</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/configuration/ramalama-oci"><span title="OCI Spec" class="linkLabel_WmDU">OCI Spec</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/docs/category/platform-guides"><span title="Platform Guides" class="categoryLinkLabel_W154">Platform Guides</span></a><button aria-label="Expand sidebar category &#x27;Platform Guides&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/docs/category/commands"><span title="Commands" class="categoryLinkLabel_W154">Commands</span></a><button aria-label="Expand sidebar category &#x27;Commands&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/misc/MACOS_INSTALL"><span title="misc" class="categoryLinkLabel_W154">misc</span></a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/docs/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/docs/category/configuration"><span>Configuration</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Configuration File</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Configuration File</h1></header>
<h1>DESCRIPTION</h1>
<p>RamaLama reads all ramalama.conf files, if they exists
and modify the defaults for running RamaLama on the host. ramalama.conf uses
a TOML format that can be easily modified and versioned.</p>
<p>RamaLama reads the he following paths for global configuration that effects all users.</p>
<table><thead><tr><th>Paths</th><th>Exception</th></tr></thead><tbody><tr><td><strong>/usr/share/ramalama/ramalama.conf</strong></td><td>On Linux</td></tr><tr><td><strong>/usr/local/share/ramalama/ramalama.conf</strong></td><td>On Linux</td></tr><tr><td><strong>/etc/ramalama/ramalama.conf</strong></td><td>On Linux</td></tr><tr><td><strong>/etc/ramalama/ramalama.conf.d/*.conf</strong></td><td>On Linux</td></tr><tr><td><strong>$HOME/.local/.pipx/venvs/usr/share/ramalama/ramalama.conf</strong></td><td>On pipx installed macOS</td></tr></tbody></table>
<p>For user specific configuration it reads</p>
<table><thead><tr><th>Paths</th><th>Exception</th></tr></thead><tbody><tr><td><strong>$XDG_CONFIG_HOME/ramalama/ramalama.conf</strong></td><td></td></tr><tr><td><strong>$XDG_CONFIG_HOME/ramalama/ramalama.conf.d/*.conf</strong></td><td></td></tr><tr><td><strong>$HOME/.config/ramalama/ramalama.conf</strong></td><td><code>$XDG_CONFIG_HOME</code> not set</td></tr><tr><td><strong>$HOME/.config/ramalama/ramalama.conf.d/*.conf</strong></td><td><code>$XDG_CONFIG_HOME</code> not set</td></tr></tbody></table>
<p>Fields specified in ramalama conf files override the default options, as well as
options in previously read ramalama conf files.</p>
<p>Config files in the <code>.d</code> directories, are added in alpha numeric sorted order and must end in <code>.conf</code>.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="environment-variables">ENVIRONMENT VARIABLES<a href="#environment-variables" class="hash-link" aria-label="Direct link to ENVIRONMENT VARIABLES" title="Direct link to ENVIRONMENT VARIABLES" translate="no">‚Äã</a></h2>
<p>If the <code>RAMALAMA_CONFIG</code> environment variable is set, all system and user
config files are ignored and only the specified config file is loaded.</p>
<h1>FORMAT</h1>
<p>The [TOML format][toml] is used as the encoding of the configuration file.
Every option is nested under its table. No bare options are used. The format of
TOML can be simplified to:</p>
<p>[table1]
option = value</p>
<p>[table2]
option = value</p>
<p>[table3]
option = value</p>
<p>[table3.subtable1]
option = value</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="ramalama-table">RAMALAMA TABLE<a href="#ramalama-table" class="hash-link" aria-label="Direct link to RAMALAMA TABLE" title="Direct link to RAMALAMA TABLE" translate="no">‚Äã</a></h2>
<p>The ramalama table contains settings to configure and manage the OCI runtime.</p>
<p><code>[[ramalama]]</code></p>
<p><strong>api</strong>=&quot;none&quot;</p>
<p>Unified API layer for Inference, RAG, Agents, Tools, Safety, Evals, and Telemetry.
Options: llama-stack, none</p>
<p><strong>api_key</strong>=&quot;&quot;</p>
<p>OpenAI-compatible API key. Can also be set via the RAMALAMA_API_KEY environment variable.</p>
<p><strong>carimage</strong>=&quot;registry.access.redhat.com/ubi10-micro<!-- -->:latest<!-- -->&quot;</p>
<p>OCI model car image</p>
<p>Image to be used when building and pushing --type=car models</p>
<p><strong>cache_reuse</strong>=256</p>
<p>Min chunk size to attempt reusing from the cache via KV shifting</p>
<p><strong>container</strong>=true</p>
<p>Run RamaLama in the default container.
RAMALAMA_IN_CONTAINER environment variable overrides this field.</p>
<p><strong>convert_type</strong>=&quot;raw&quot;</p>
<p>Convert the MODEL to the specified OCI Object
Options: artifact, car, raw</p>
<table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody><tr><td>artifact</td><td>Store AI Models as artifacts</td></tr><tr><td>car</td><td>Traditional OCI image including base image with the model stored in a /models subdir</td></tr><tr><td>raw</td><td>Traditional OCI image including only the model and a link file <code>model.file</code> pointed at it stored at /</td></tr></tbody></table>
<p><strong>ctx_size</strong>=0</p>
<p>Size of the prompt context (0 = loaded from model)</p>
<p><strong>engine</strong>=&quot;podman&quot;</p>
<p>Run RamaLama using the specified container engine.
Valid options are: Podman and Docker
This field can be overridden by the RAMALAMA_CONTAINER_ENGINE environment variable.</p>
<p><strong>env</strong>=[]</p>
<p>Environment variables to be added to the environment used when running in a container engine (e.g., Podman, Docker). For example &quot;LLAMA_ARG_THREADS=10&quot;.</p>
<p><strong>gguf_quantization_mode</strong>=&quot;Q4_K_M&quot;</p>
<p>The quantization mode used when creating OCI formatted AI Models.
Available options: Q2_K, Q3_K_S, Q3_K_M, Q3_K_L, Q4_0, Q4_K_S, Q4_K_M, Q5_0, Q5_K_S, Q5_K_M, Q6_K, Q8_0.</p>
<p><strong>host</strong>=&quot;0.0.0.0&quot;</p>
<p>IP address for llama.cpp to listen on.</p>
<p><strong>image</strong>=&quot;quay.io/ramalama/ramalama<!-- -->:latest<!-- -->&quot;</p>
<p>OCI container image to run with the specified AI model
RAMALAMA_IMAGE environment variable overrides this field.</p>
<p><code>[[ramalama.images]]</code>
HIP_VISIBLE_DEVICES    = &quot;quay.io/ramalama/rocm&quot;
CUDA_VISIBLE_DEVICES   = &quot;quay.io/ramalama/cuda&quot;
ASAHI_VISIBLE_DEVICES  = &quot;quay.io/ramalama/asahi&quot;
INTEL_VISIBLE_DEVICES  = &quot;quay.io/ramalama/intel-gpu&quot;
ASCEND_VISIBLE_DEVICES = &quot;quay.io/ramalama/cann&quot;
MUSA_VISIBLE_DEVICES   = &quot;quay.io/ramalama/musa&quot;
VLLM                   = &quot;registry.redhat.io/rhelai1/ramalama-vllm&quot;</p>
<p>Alternative images to use when RamaLama recognizes specific hardware or user
specified vllm model runtime.</p>
<p><strong>keep_groups</strong>=false</p>
<p>Pass <code>--group-add keep-groups</code> to podman, when using podman.
In some cases this is needed to access the gpu from a rootless container</p>
<p><strong>log_level</strong>=warning
Set the logging level of RamaLama application.
Valid Values:
debug, info, warning, error, critical</p>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>--debug option overrides this field and forces the system to debug</p></div></div>
<p><strong>max_tokens</strong>=0</p>
<p>Maximum number of tokens to generate. Set to 0 for unlimited output (default: 0).
This parameter is mapped to the appropriate runtime-specific parameter when executing models.</p>
<p><strong>ngl</strong>=-1</p>
<p>number of gpu layers, 0 means CPU inferencing, 999 means use max layers (default: -1)
The default -1, means use whatever is automatically deemed appropriate (0 or 999)</p>
<p><strong>prefix</strong>=&quot;&quot;
Specify default prefix for chat and run command. By default the prefix
is based on the container engine used.</p>
<table><thead><tr><th>Container Engine</th><th>Prefix</th></tr></thead><tbody><tr><td>Podman</td><td>&quot;ü¶≠ &gt; &quot;</td></tr><tr><td>Docker</td><td>&quot;üêã &gt; &quot;</td></tr><tr><td>No Engine</td><td>&quot;ü¶ô &gt; &quot;</td></tr><tr><td>No EMOJI support</td><td>&quot;&gt; &quot;</td></tr></tbody></table>
<p><strong>port</strong>=&quot;8080&quot;</p>
<p>Specify initial port for a range of 101 ports for services to listen on.
If this port is unavailable, another free port from this range will be selected.</p>
<p><strong>pull</strong>=&quot;newer&quot;</p>
<ul>
<li class=""><strong>always</strong>: Always pull the image and throw an error if the pull fails.</li>
<li class=""><strong>missing</strong>: Only pull the image when it does not exist in the local containers storage. Throw an error if no image is found and the pull fails.</li>
<li class=""><strong>never</strong>: Never pull the image but use the one from the local containers storage. Throw an error when no image is found.</li>
<li class=""><strong>newer</strong>: Pull if the image on the registry is newer than the one in the local containers storage. An image is considered to be newer when the digests are different. Comparing the time stamps is prone to errors. Pull errors are suppressed if a local image was found.</li>
</ul>
<p><strong>rag_format</strong>=&quot;qdrant&quot;</p>
<p>Specify the default output format for output of the <code>ramalama rag</code> command.
Options: qdrant, json, markdown, milvus.</p>
<p><strong>rag_images</strong>=&quot;quay.io/ramalama/ramalama-rag&quot;</p>
<p>OCI container image to run with the specified AI model when using RAG content.</p>
<p><code>[[ramalama.rag_images]]</code>
CUDA_VISIBLE_DEVICES   = &quot;quay.io/ramalama/cuda-rag&quot;
HIP_VISIBLE_DEVICES    = &quot;quay.io/ramalama/rocm-rag&quot;
INTEL_VISIBLE_DEVICES  = &quot;quay.io/ramalama/intel-gpu-rag&quot;
GGML_VK_VISIBLE_DEVICES = &quot;quay.io/ramalama/ramalama&quot;</p>
<p><strong>runtime</strong>=&quot;llama.cpp&quot;</p>
<p>Specify the AI runtime to use; valid options are &#x27;llama.cpp&#x27;, &#x27;vllm&#x27;, and &#x27;mlx&#x27; (default: llama.cpp)
Options: llama.cpp, vllm, mlx</p>
<p><strong>selinux</strong>=false</p>
<p>SELinux container separation enforcement</p>
<p><strong>store</strong>=&quot;$HOME/.local/share/ramalama&quot;</p>
<p>Store AI Models in the specified directory</p>
<p><strong>summarize_after</strong>=4</p>
<p>Automatically summarize conversation history after N messages to prevent context growth.
When enabled, ramalama will periodically condense older messages into a summary,
keeping only recent messages and the summary. This prevents the context from growing
indefinitely during long chat sessions. Set to 0 to disable (default: 4).</p>
<p><strong>temp</strong>=&quot;0.8&quot;
Temperature of the response from the AI Model
llama.cpp explains this as:</p>
<p>The lower the number is, the more deterministic the response.</p>
<p>The higher the number is the more creative the response is, but more likely to hallucinate when set too high.</p>
<p>Usage: Lower numbers are good for virtual assistants where we need deterministic responses. Higher numbers are good for roleplay or creative tasks like editing stories</p>
<p><strong>thinking</strong>=true</p>
<p>Enable thinking mode on reasoning models</p>
<p><strong>threads</strong>=-1</p>
<p>maximum number of cpu threads to use for inferencing
The default -1, uses the default of the underlying implementation</p>
<p><strong>transport</strong>=&quot;ollama&quot;</p>
<p>Specify the default transport to be used for pulling and pushing of AI Models.
Options: oci, ollama, huggingface.
RAMALAMA_TRANSPORT environment variable overrides this field.</p>
<p><code>[[ramalama.http_client]]</code></p>
<p>Http client configuration</p>
<p><strong>max_retries</strong>=5</p>
<p>The maximum number of times to retry a failed download</p>
<p><strong>max_retry_delay</strong>=30</p>
<p>The maximum delay between retry attempts in seconds</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="ramalamaprovider-table">RAMALAMA.PROVIDER TABLE<a href="#ramalamaprovider-table" class="hash-link" aria-label="Direct link to RAMALAMA.PROVIDER TABLE" title="Direct link to RAMALAMA.PROVIDER TABLE" translate="no">‚Äã</a></h2>
<p>The <code>ramalama.provider</code> table configures hosted API providers that RamaLama can proxy to.</p>
<p><code>[[ramalama.provider]]</code></p>
<p><strong>openai</strong>=&quot;&quot;</p>
<p>Configuration settings for the openai hosted provider</p>
<p><code>[[ramalama.provider.openai]]</code></p>
<p><strong>api_key</strong>=&quot;&quot;</p>
<p>Provider-specific API key used when invoking OpenAI-hosted transports. Overrides <code>RAMALAMA_API_KEY</code> when set.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="ramalamabenchmarks-table">RAMALAMA.BENCHMARKS TABLE<a href="#ramalamabenchmarks-table" class="hash-link" aria-label="Direct link to RAMALAMA.BENCHMARKS TABLE" title="Direct link to RAMALAMA.BENCHMARKS TABLE" translate="no">‚Äã</a></h2>
<p>The ramalama.benchmarks table contains benchmark related settings.</p>
<p><code>[[ramalama.benchmarks]]</code></p>
<p><strong>storage_folder</strong>=&quot;&lt;default store&gt;/benchmarks&quot;</p>
<p>Manually specify where to save benchmark results.
By default, this will be stored in the default model store directory under <code>benchmarks/</code>.
Changing <code>ramalama.store</code> does not update this; set <code>ramalama.benchmarks.storage_folder</code> explicitly if needed.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="ramalamauser-table">RAMALAMA.USER TABLE<a href="#ramalamauser-table" class="hash-link" aria-label="Direct link to RAMALAMA.USER TABLE" title="Direct link to RAMALAMA.USER TABLE" translate="no">‚Äã</a></h2>
<p>The ramalama.user table contains user preference settings.</p>
<p><code>[[ramalama.user]]</code></p>
<p><strong>no_missing_gpu_prompt</strong>=false</p>
<p>Suppress the interactive prompt when running on macOS with a Podman VM that does not support GPU acceleration (e.g., applehv provider). When set to true, RamaLama will automatically proceed without GPU support instead of prompting the user for confirmation. This is useful for automation and scripting scenarios where interactive prompts are not desired.</p>
<p>Can also be set via the RAMALAMA_USER__NO_MISSING_GPU_PROMPT environment variable.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/containers/ramalama/edit/main/docsite/configuration/conf.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/category/configuration"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Configuration</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/configuration/ramalama-oci"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">OCI Spec</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#environment-variables" class="table-of-contents__link toc-highlight">ENVIRONMENT VARIABLES</a></li><li><a href="#ramalama-table" class="table-of-contents__link toc-highlight">RAMALAMA TABLE</a></li><li><a href="#ramalamaprovider-table" class="table-of-contents__link toc-highlight">RAMALAMA.PROVIDER TABLE</a></li><li><a href="#ramalamabenchmarks-table" class="table-of-contents__link toc-highlight">RAMALAMA.BENCHMARKS TABLE</a></li><li><a href="#ramalamauser-table" class="table-of-contents__link toc-highlight">RAMALAMA.USER TABLE</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/getting-started/installation">Getting Started</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/commands/ramalama/">API References</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/containers/ramalama/issues" target="_blank" rel="noopener noreferrer" class="footer__link-item">Issues<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://matrix.to/#/#ramalama:fedoraproject.org" target="_blank" rel="noopener noreferrer" class="footer__link-item">Matrix<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://discord.gg/MkCXuTRBUn" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://x.com/RamaLamaLabs" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://blog.ramalama.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Blog<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://github.com/containers/ramalama" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright ¬© 2026 RamaLama Contributors.</div></div></div></footer></div>
</body>
</html>